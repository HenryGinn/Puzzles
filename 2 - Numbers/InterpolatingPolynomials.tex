\subsection{Interpolating Polynomials}

This subsection is about a series of results I found about interpolating polynomials that are all linked together. I found these at several different points throughout my mathematical journey, and have attempted to present them in a way that highlights how one might discover them for themselves.

\subsubsection{Calculus of Differences and $n^\text{th}$ Term Rule}

The $n^\text{th}$ term rule is a function from the natural numbers excluding 0 to the reals that generates a sequence. In year 9 we were shown a method to find the $n^\text{th}$ term rule for a sequence generated by a quadratic polynomial that confused me, and when I investigated this for myself I found an extension to higher orders. I did not prove that this always worked at the time, and did so when I revisited the topic during my maths masters. Determining a cubic polynomial for a four term sequence was one of the very first programs I wrote soon after I turned 15. During the winter holiday I wrote a version that could find the polynomial for arbitrary length sequences.



\subsubsection{The Lagrange Interpolating Polynomial}

In my second year of undergrad I was doing problem sheet 1 from part A linear algebra~\cite{PartALinearAlgebraSheet1}, and question two was the following.

\begin{center}
    (Harder) Show that the space of functions $f : \mathbb{N} \to \mathbb{R}$ does not have a countable basis.
\end{center}

I was not initially convinced by this and thought that a polynomial interpolating all the points of $f$ would be a counterexample. I have discussed why this reasoning is wrong in the extensions and comments, along with the answer to the original question. I am also not sure why I did not realise I had my supposed counterexample from the calculus of differences method, but nonetheless I found a new method that is the subject of this exercise. If I was a teacher then I would definitely be giving this problem to my students.

Given a finite set, $A \subset \mathbb{R}$, and a function $f : A \to \mathbb{R}$, find an  interpolating polynomial of lowest degree, $p : A \to \mathbb{R}$. That is $f(x_i) = p(x_i) \quad \forall x_i \in A$. This is known as the Lagrange Interpolating Polynomial, or simply the Lagrange Polynomial. Finding an explicit formula is the first part of the question, and showing it is minimal is the second part.

\textbf{Hints:}

\begin{enumerate}
    \item Use linearity - the finite sum of a collection of polynomials is also a polynomial.
    \item Find a way to focus on one point at a time.
    \item Use the factor theorem - a polyomial has a root at $x_0$ if and only if it divides $x - x_0$.
\end{enumerate}

\textbf{Solution:}

The key to this problem is to use the fact that two polynomials can be added to get another polynomial. For each point, $(x_i, y_i)$, we can find a polynomial, $p_i(x)$, that is $0$ when evaluated on all $x_j$ where $j \ne i$ and satisfies $p(x_i) = y_i$. The sum of these polynomials gives us an interpolating polynomial by equation~\eqref{eqn:InterpolatingPolynomials_LagrangePolynomialInterpolates}.

\begin{equation}
	p(x_i) = \sum_j^n p_j(x_j) = \sum_j^n y_i \delta_{ij} = y_i
	\label{eqn:InterpolatingPolynomials_LagrangePolynomialInterpolates}
\end{equation}

The problem now reduces to finding each of the $p_i$. In fact we can simplify the problem further as we only need to find a function, $q_i$, that is $0$ for $x_j$ for $j \ne i$ and satisfies $q_i(x_i) \ne 0$. Once such a function has been found, we can define $p_i$ as in equation~\eqref{eqn:InterpolatingPolynomials_LagrangePolynomialDefiningPi}. We can now deduce $q_i$ using the factor theorem: $x_0$ is a root of $p$ if and only if $p(x)$ divides $x - x_0$. This gives $q_i$ as the product in equation~\eqref{eqn:InterpolatingPolynomials_LagrangePolynomialDefiningQi}. The final polynomial is given in~\eqref{eqn:InterpolatingPolynomials_LagrangePolynomialDefiningP}.

\begin{subequations}
	\begin{equation}
		p_i(x) = \frac{q_i(x)}{q_i(x_i)} \cdot y_i
		\label{eqn:InterpolatingPolynomials_LagrangePolynomialDefiningPi}
	\end{equation}\vspace{-2mm}
	
	\begin{equation}
		q_i(x) = \prod_{\substack{j=1 \\ j \ne i}}^n (x - x_j)
		\label{eqn:InterpolatingPolynomials_LagrangePolynomialDefiningQi}
	\end{equation}\vspace{-2mm}
	
	\begin{equation}
	p(x) = \sum_{i=1}^n \prod_{\substack{j=1 \\ j \ne i}}^n \frac{x - x_i}{x_j - x_i} y_i
	\label{eqn:InterpolatingPolynomials_LagrangePolynomialDefiningP}
	\end{equation}
\end{subequations}

Now that an interpolating polynomial has been constructed, it is necessary to show it is of minimal order. We assume that the $n$ coordinates, $(x_i, y_i)$, are interpolated by a polynomial of order one less than what is needed in general, $\sum_{k=0}^{n-2} a_k x^k$. This gives a formula for $y_i$ in terms of $x_i$ which can be substituted into equation~\eqref{eqn:InterpolatingPolynomials_LagrangePolynomialDefiningP} and defines the polynomial $\sum_{k=0}^{n-1} b_k x^k$ as demonstrated in equation~\eqref{eqn:InterpolatingPolynomials_SubstituteDegeneratePoints}.

\begin{subequations}
	\begin{align}
		p(x) &= \sum_{i=1}^n \sum_{j \ne i} \frac{x - x_j}{x_i - x_j} y_i  \\
		&= \sum_{i=1}^n \sum_{j \ne i} \left( \frac{x - x_j}{x_i - x_j} \sum_{k=0}^{n-2} a_k x^k \right)  \\
		&= \sum_{k=0}^{n-2} a_k \sum_{i=1}^n \sum_{j \ne i} \frac{1}{x_i - x_j} (x^{k+1} - x_j x^k)  \\
		&= \sum_{k=0}^{n-1} b_k x^k
	\end{align}\vspace{-5mm}
	\label{eqn:InterpolatingPolynomials_SubstituteDegeneratePoints}
\end{subequations}

The aim is to show that the generated interpolating polynomial has a degree no higher than necessary to interpolate the points. This means we need to show that $b_{n-1} = 0$ which is done below in equation~\eqref{eqn:InterpolatingPolynomials_HighestPowerCoefficientIsZero}. In equation~\eqref{eqn:InterpolatingPolynomials_HighestPowerCoefficientIsZeroC} we have made the substitution $i = n + 1 - l$ and $j = n + 1 - m$. It is easy to see that the range $i = 1, \dots, n$ is equivalent to $l = 1, \dots, n$, and the same for $j$ and $m$ respectively (the other is just reversed) so the outer sums are the same. $i < j \iff n + 1 - l < n + 1 - m \iff -l < -m \iff l > m$ shows that the inner sums are over the same range as well.

\begin{subequations}
	\begin{align}
		b_{n-1} &= a_{n-2} \sum_{i=1}^n \sum_{j \ne n} \frac{1}{x_i - x_j}  \\
		&= a_{n-2} \left( \sum_{i=1}^n \sum_{j<i} \frac{1}{x_i - x_j} + \sum_{i=1}^n \sum_{j>i} \frac{1}{x_i - x_j} \right)  \\
		&= a_{n-2} \left( \sum_{i=1}^n \sum_{j<i} \frac{1}{x_i - x_j} + \sum_{l=1}^n \sum_{m<l} \frac{1}{x_l - x_m} \right)\label{eqn:InterpolatingPolynomials_HighestPowerCoefficientIsZeroC}  \\
		&= a_{n-2} \left( \sum_{i=1}^n \sum_{j<i} \frac{1}{x_i - x_j} + \sum_{i=1}^n \sum_{j<i} \frac{1}{x_i - x_j}\right)  \\
		&= a_{n-2} \sum_{i=1}^n \sum_{j<i} \left( \frac{1}{x_i - x_j} - \frac{1}{x_i - x_j}\right)  \\
		&= 0
	\end{align}
	\label{eqn:InterpolatingPolynomials_HighestPowerCoefficientIsZero}
\end{subequations}

So far we have only demonstrated that the generated interpolating polynomial will be of minimal order when the $n$ coordinates to be interpolated can be fit by a polynomial of degree $n - 1$ or $n - 2$. It is therefore necessary to show that even more degenerate sets of coordinates also give rise to minimal order interpolating polynomials. Suppose the coordinates can be interpolated by a polynomial of degree $k - 1$ where $k < n$.

Choosing any $k$ of the $n$ coordinates will generate a minimum degree interpolating polynomial. We will show later that the minimum degree polynomial is unique, and therefore the same polynomial is generated by any of the $k$ coordinates. By the above algebra we know that interpolating any $k + 1$ coordinates will generate the same polynomial as generated by a subset of the $k + 1$ coordinates of size $k$. This logic can be continued by induction, eventually interpolating all $n$ coordinates.

\textbf{Extensions and Comments:}

% Discuss the numerical instability of the polynomial as presented here

\subsubsection{Properties of Resulting Polynomials}

% Minimality of polynomials
% Uniqueness of minimal interpolating polynomial through Vandermonde determinant
% Combining these properties to show equality from the two methods















